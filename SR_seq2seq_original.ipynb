{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SR_seq2seq_original.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulahad89/Encoder-Decoder-based-Translation-Model/blob/main/SR_seq2seq_original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtHoOGfJuS-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3786046d-226b-4179-9598-a1887f029cf5"
      },
      "source": [
        "pip install AudioSegment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: AudioSegment in /usr/local/lib/python3.6/dist-packages (0.23.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (from AudioSegment) (0.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from AudioSegment) (1.18.5)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.6/dist-packages (from AudioSegment) (2.0.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "785nOulGuEJd"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "import warnings\n",
        "import glob \n",
        "from pydub import AudioSegment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL6SNz1M49bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e334dd93-cc3b-45f4-c448-45a5dca150fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rQWQNe16ZVF"
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/Sajid_Project_Grading/SR/full_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owbHH-rgqUBD"
      },
      "source": [
        "aud_data = []\n",
        "path_2 = 'drive/My Drive/Sajid_Project_Grading/SR/clips_wavfiles'\n",
        "for wav in data['path']:\n",
        "    samples , sample_rate = librosa.load(path_2 +'/'+ wav[:-4] + '.wav',16000) \n",
        "    samples = librosa.resample(samples, sample_rate, 8000)\n",
        "    aud_data.append(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BGfejP40c0k"
      },
      "source": [
        "max_input_len = max(len(sen) for sen in aud_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIS726KB0inP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef80bc88-b3b2-438c-e726-af9137429cf3"
      },
      "source": [
        "max_input_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUrOn6wWLUJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "602a8dcb-1cc7-4f30-ceed-ed70f632ce26"
      },
      "source": [
        "print(aud_data[25])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -3.6458505e-06\n",
            " -5.4983611e-06  9.1177344e-06]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIr5mSA-8EYW"
      },
      "source": [
        "import os, sys\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj83mf9c49NQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8376d45-6869-4725-b1a7-4fb32febbaf8"
      },
      "source": [
        "sen_len = data['sentence'].apply(lambda x: len(x.split(' ')))\n",
        "max(sen_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lCPZs5x8EgL"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 8\n",
        "LSTM_NODES =256\n",
        "NUM_SENTENCES = 161\n",
        "MAX_SENTENCE_LENGTH = max(sen_len)\n",
        "MAX_NUM_WORDS = 5000\n",
        "EMBEDDING_SIZE = 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK36piOj8EnI"
      },
      "source": [
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "\n",
        "count = 0\n",
        "for i in range(161):\n",
        "    count += 1\n",
        "\n",
        "    if count > NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    output = data.iloc[i,3]\n",
        "\n",
        "    output_sentence = output + ' <eos>'\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSkU4T3X8TZO"
      },
      "source": [
        "#Tokenizing output sequences and 1 palce shifted o/p sequences as an input to o/p \n",
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLYTigRA8-lq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3fe28b7-b429-44e9-9e23-92c15fac6403"
      },
      "source": [
        "output_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<eos>': 1,\n",
              " '<sos>': 2,\n",
              " 'ਅਕਾਲ': 519,\n",
              " 'ਅਕਾਲੀਆਂ': 367,\n",
              " 'ਅਖਿਆ': 327,\n",
              " 'ਅਗਰ': 376,\n",
              " 'ਅਗੰਮੜੇ': 550,\n",
              " 'ਅਜੇ': 611,\n",
              " 'ਅਤੇ': 57,\n",
              " 'ਅਧਿਕਾਰ': 287,\n",
              " 'ਅਨਮੋਲ': 410,\n",
              " 'ਅਫ਼ਸੋਸ': 388,\n",
              " 'ਅਭਿਨਵ': 691,\n",
              " 'ਅਭੁੱਲ': 526,\n",
              " 'ਅਮਰੀਕਾ': 453,\n",
              " 'ਅਮੀਰ': 495,\n",
              " 'ਅਮੀਰੀ': 196,\n",
              " 'ਅਸਤਿਤੱਵ': 415,\n",
              " 'ਅਸਲੀਅਤ': 103,\n",
              " 'ਅਸੀਂ': 52,\n",
              " 'ਅੜੀਅਲ': 573,\n",
              " 'ਅੰਗਰੇਜ਼ੀ': 261,\n",
              " 'ਅੰਦਰ': 101,\n",
              " 'ਅੰਦਾਜ਼': 571,\n",
              " 'ਅੰਮ੍ਰਿਤ': 311,\n",
              " 'ਅੱਖੀਆਂ': 677,\n",
              " 'ਅੱਗੇ': 106,\n",
              " 'ਅੱਜ': 41,\n",
              " 'ਅੱਟੀ': 577,\n",
              " 'ਆਂਵਦਾ': 683,\n",
              " 'ਆਇਆ': 63,\n",
              " 'ਆਈ': 71,\n",
              " 'ਆਕਸੀਜਨ': 305,\n",
              " 'ਆਖ': 520,\n",
              " 'ਆਖਿਆ': 323,\n",
              " 'ਆਤਮਾ': 331,\n",
              " 'ਆਦੀ': 259,\n",
              " 'ਆਪ': 253,\n",
              " 'ਆਪਣਾ': 68,\n",
              " 'ਆਪਣੀ': 129,\n",
              " 'ਆਪਣੇ': 64,\n",
              " 'ਆਫ਼ਰਿਆ': 633,\n",
              " 'ਆਮ': 605,\n",
              " 'ਆਸ਼੍ਰਮ': 477,\n",
              " 'ਇਕ': 107,\n",
              " 'ਇਕੱਠ': 176,\n",
              " 'ਇਥੇ': 609,\n",
              " 'ਇਨ੍ਹਾਂ': 506,\n",
              " 'ਇਸ': 14,\n",
              " 'ਇਹ': 18,\n",
              " 'ਇਹਨੂੰ': 255,\n",
              " 'ਇਹੀ': 527,\n",
              " 'ਇੱਕ': 33,\n",
              " 'ਈ': 135,\n",
              " 'ਉਕਤ': 479,\n",
              " 'ਉਣੱਤਰਵੇਂ': 208,\n",
              " 'ਉਦੋਂ': 602,\n",
              " 'ਉਨਾਂ': 383,\n",
              " 'ਉਨ੍ਹਾਂ': 126,\n",
              " 'ਉਮਰ': 123,\n",
              " 'ਉਮਰੇ': 658,\n",
              " 'ਉਸ': 31,\n",
              " 'ਉਸਨੂੰ': 617,\n",
              " 'ਉਸੇ': 81,\n",
              " 'ਉਹ': 17,\n",
              " 'ਉਹਦੀ': 121,\n",
              " 'ਉਹਦੇ': 118,\n",
              " 'ਉਹਨਾਂ': 125,\n",
              " 'ਉੱਚ': 551,\n",
              " 'ਉੱਚਾ': 230,\n",
              " 'ਏ': 148,\n",
              " 'ਏਨੀ': 181,\n",
              " 'ਐ': 352,\n",
              " 'ਐਸੀ': 396,\n",
              " 'ਓ': 132,\n",
              " 'ਓਹੀ': 598,\n",
              " 'ਔਰਤ': 223,\n",
              " 'ਕਣਕ': 218,\n",
              " 'ਕਣੀ': 592,\n",
              " 'ਕਦੇ': 61,\n",
              " 'ਕਨਿੰਘਮ': 154,\n",
              " 'ਕਬਰਸਤਾਨ': 338,\n",
              " 'ਕਬੱਡੀ': 48,\n",
              " 'ਕਮਰ': 600,\n",
              " 'ਕਰ': 23,\n",
              " 'ਕਰਕੇ': 133,\n",
              " 'ਕਰਦੇ': 375,\n",
              " 'ਕਰਨ': 39,\n",
              " 'ਕਰਮਾਂ': 418,\n",
              " 'ਕਰਵਾਇਆ': 217,\n",
              " 'ਕਰੀਂ': 404,\n",
              " 'ਕਰੋ': 283,\n",
              " 'ਕਲੀ': 332,\n",
              " 'ਕਲੱਬਾਂ': 576,\n",
              " 'ਕਵੀ': 636,\n",
              " 'ਕਸ਼ਮੀਰੀ': 485,\n",
              " 'ਕਹਿੰਦਾ': 568,\n",
              " 'ਕਾਬੂ': 171,\n",
              " 'ਕਾਰਣ': 303,\n",
              " 'ਕਾਰਾ': 241,\n",
              " 'ਕਾਰੋਬਾਰ': 580,\n",
              " 'ਕਾਲਜ': 104,\n",
              " 'ਕਾਲਾਂ': 541,\n",
              " 'ਕਿ': 91,\n",
              " 'ਕਿਧਰੇ': 238,\n",
              " 'ਕਿਰਤ': 402,\n",
              " 'ਕਿਰਦਾਰ': 698,\n",
              " 'ਕਿਸਮ': 669,\n",
              " 'ਕਿਸਾਨਾਂ': 213,\n",
              " 'ਕਿਹਾ': 88,\n",
              " 'ਕਿੰਨੀ': 491,\n",
              " 'ਕਿੱਕਰ': 333,\n",
              " 'ਕਿੱਥੇ': 179,\n",
              " 'ਕੀ': 119,\n",
              " 'ਕੀਤਾ': 474,\n",
              " 'ਕੀਤੇ': 670,\n",
              " 'ਕੁਦਰਤ': 409,\n",
              " 'ਕੁਮਾਰੀ': 430,\n",
              " 'ਕੁਮੈਂਟਰੀ': 501,\n",
              " 'ਕੁਰਬਾਨ': 142,\n",
              " 'ਕੁੱਝ': 111,\n",
              " 'ਕੁੱਲ': 82,\n",
              " 'ਕੇ': 16,\n",
              " 'ਕੈਨੇਡਾ': 270,\n",
              " 'ਕੈਨੇਡੀਅਨ': 579,\n",
              " 'ਕੋ': 313,\n",
              " 'ਕੋਈ': 73,\n",
              " 'ਕੋਲ਼': 169,\n",
              " 'ਕੋਲੋਂ': 131,\n",
              " 'ਕੌਮਾਂ': 634,\n",
              " 'ਕੰਡੀਸ਼ਨਰ': 163,\n",
              " 'ਕੰਪਨੀ': 281,\n",
              " 'ਕੰਮ': 54,\n",
              " 'ਕੱਪ': 374,\n",
              " 'ਕੱਲੂ': 334,\n",
              " 'ਖਤਮ': 339,\n",
              " 'ਖਰਚਾ': 435,\n",
              " 'ਖਲੋਤੇ': 666,\n",
              " 'ਖਾਂਦੇ': 597,\n",
              " 'ਖਾਣ': 134,\n",
              " 'ਖਾਲਸਾ': 137,\n",
              " 'ਖਾਲੀ': 235,\n",
              " 'ਖਿਡਾਰੀ': 120,\n",
              " 'ਖੁਸ਼ੀ': 632,\n",
              " 'ਖੇਡਣਾ': 264,\n",
              " 'ਖੇਡਾ': 503,\n",
              " 'ਖੇਡਾਂ': 182,\n",
              " 'ਖੜ੍ਹਾ': 442,\n",
              " 'ਗਈ': 674,\n",
              " 'ਗਈਆਂ': 679,\n",
              " 'ਗਏ': 99,\n",
              " 'ਗਰੀਬ': 496,\n",
              " 'ਗਰੀਬੀ': 197,\n",
              " 'ਗਲਵੱਕੜੀ': 193,\n",
              " 'ਗਲੀਆਂ': 139,\n",
              " 'ਗਾਹਕ': 384,\n",
              " 'ਗਿਆ': 44,\n",
              " 'ਗੁਆਂਢੀਆਂ': 157,\n",
              " 'ਗੁਰਸ਼ਰਨ': 358,\n",
              " 'ਗੁਰੂ': 649,\n",
              " 'ਗੇਟ': 424,\n",
              " 'ਗੋਲਡ': 688,\n",
              " 'ਗੱਲ': 43,\n",
              " 'ਗੱਲਾਂ': 46,\n",
              " 'ਘਟਨਾ': 481,\n",
              " 'ਘਰ': 145,\n",
              " 'ਘਰਿ': 343,\n",
              " 'ਘੁਟ': 92,\n",
              " 'ਘੁੱਟ': 192,\n",
              " 'ਚ': 79,\n",
              " 'ਚਕਰਾ': 76,\n",
              " 'ਚਲਦੈ': 504,\n",
              " 'ਚਲਾਈ': 190,\n",
              " 'ਚਲਾਏ': 365,\n",
              " 'ਚਲੇ': 548,\n",
              " 'ਚਲੋ': 505,\n",
              " 'ਚਾਹੀਦਾ': 434,\n",
              " 'ਚਾਹੀਦੈ': 165,\n",
              " 'ਚਾਹੁੰਦੀ': 195,\n",
              " 'ਚੀਰ': 462,\n",
              " 'ਚੁੱਕ': 237,\n",
              " 'ਚੁੱਕਣਾ': 433,\n",
              " 'ਚੁੱਕੇ': 279,\n",
              " 'ਚੁੱਪ': 665,\n",
              " 'ਚੰਗਾ': 265,\n",
              " 'ਚੰਦ': 110,\n",
              " 'ਚੱਲ': 659,\n",
              " 'ਚੱਲਦੀ': 191,\n",
              " 'ਚੱਲਦੇ': 351,\n",
              " 'ਛਕਣ': 403,\n",
              " 'ਛਡ੍ਹੋ': 268,\n",
              " 'ਛੁੱਟ': 316,\n",
              " 'ਛੇ': 232,\n",
              " 'ਛੇਤੀ': 641,\n",
              " 'ਛੋਟਾ': 185,\n",
              " 'ਛੋਟੀ': 657,\n",
              " 'ਛੱਡ': 547,\n",
              " 'ਛੱਡਿਆ': 147,\n",
              " 'ਜਥੇਦਾਰ': 294,\n",
              " 'ਜਦੋਂ': 684,\n",
              " 'ਜਮਾਂਵਾਂਗਾ': 288,\n",
              " 'ਜਰੂਰੀ': 610,\n",
              " 'ਜਵਾਨ': 267,\n",
              " 'ਜਵਾਬ': 360,\n",
              " 'ਜਹਿਰ': 98,\n",
              " 'ਜਾ': 590,\n",
              " 'ਜਾਂ': 173,\n",
              " 'ਜਾਂਚ': 662,\n",
              " 'ਜਾਂਦੀ': 574,\n",
              " 'ਜਾਂਦੇ': 51,\n",
              " 'ਜਾਂਦੈ': 89,\n",
              " 'ਜਾਇਦਾਦ': 661,\n",
              " 'ਜਾਗਣ': 637,\n",
              " 'ਜਾਣੂ': 216,\n",
              " 'ਜਾਵੇ': 224,\n",
              " 'ਜਿਊਣ': 177,\n",
              " 'ਜਿਸ': 55,\n",
              " 'ਜਿਹਾ': 544,\n",
              " 'ਜਿਹੀ': 372,\n",
              " 'ਜਿਹੜੇ': 533,\n",
              " 'ਜਿੰਦੇ': 405,\n",
              " 'ਜੀ': 37,\n",
              " 'ਜੇਲ੍ਹਾਂ': 233,\n",
              " 'ਜੋ': 596,\n",
              " 'ਜੋਗੀਏ': 178,\n",
              " 'ਜੰਗ': 671,\n",
              " 'ਝਪਕੀਆਂ': 174,\n",
              " 'ਝਲਕ': 329,\n",
              " 'ਝੂਠੇ': 534,\n",
              " 'ਝੇਡਾਂ': 226,\n",
              " 'ਝੇਲ': 278,\n",
              " 'ਟਰੱਕ': 350,\n",
              " 'ਟੀਕਾ': 406,\n",
              " 'ਟੁੱਕ': 499,\n",
              " 'ਟੈਕਸੀ': 167,\n",
              " 'ਟੈਨਿਸ': 263,\n",
              " 'ਟੈਲੀਫੋਨ': 540,\n",
              " 'ਟੋਰੀਆਂ': 399,\n",
              " 'ਡਾਇਰੈਕਟਰ': 467,\n",
              " 'ਡਾਲਰ': 437,\n",
              " 'ਡੌਨ': 697,\n",
              " 'ਢੁੱਡੀਕੇ': 117,\n",
              " 'ਢੋਂਗ': 392,\n",
              " 'ਢੱਕ': 538,\n",
              " 'ਤਕਰਾਰ': 302,\n",
              " 'ਤਰਸ': 546,\n",
              " 'ਤਰ੍ਹਾਂ': 336,\n",
              " 'ਤਾਂ': 25,\n",
              " 'ਤਾਰੇ': 489,\n",
              " 'ਤਿਆਰ': 500,\n",
              " 'ਤਿਹਾੜ': 231,\n",
              " 'ਤਿੰਨ': 69,\n",
              " 'ਤੁਝ': 312,\n",
              " 'ਤੁਫੈਲ': 289,\n",
              " 'ਤੁਰ': 234,\n",
              " 'ਤੁਸੀਂ': 40,\n",
              " 'ਤੁਹਾਡੇ': 475,\n",
              " 'ਤੇ': 8,\n",
              " 'ਤੋਂ': 26,\n",
              " 'ਤੋਹਫਾ': 411,\n",
              " 'ਤੌਰ': 211,\n",
              " 'ਤਜ਼ਰਬੇ': 667,\n",
              " 'ਤੰਗ': 371,\n",
              " 'ਤੰਦਰੁਸਤ': 494,\n",
              " 'ਤੱਕ': 685,\n",
              " 'ਤੱਤ': 638,\n",
              " 'ਥਾਂ': 105,\n",
              " 'ਥੋੜ੍ਹੀ': 664,\n",
              " 'ਦ': 552,\n",
              " 'ਦਾ': 5,\n",
              " 'ਦਾਤ': 320,\n",
              " 'ਦਾਤਾ': 321,\n",
              " 'ਦਾਦਾ': 470,\n",
              " 'ਦਾਦੀ': 471,\n",
              " 'ਦਿਆਂ': 141,\n",
              " 'ਦਿਨਾਂ': 524,\n",
              " 'ਦਿੰਦੀ': 380,\n",
              " 'ਦਿੰਦੀਆਂ': 623,\n",
              " 'ਦਿੰਦੇ': 386,\n",
              " 'ਦੀ': 4,\n",
              " 'ਦੀਆਂ': 29,\n",
              " 'ਦੁਪਹਿਰ': 172,\n",
              " 'ਦੁਪਹਿਰਾਂ': 445,\n",
              " 'ਦੁਬਾਰਾ': 618,\n",
              " 'ਦੁੱਧ': 545,\n",
              " 'ਦੂ': 310,\n",
              " 'ਦੂਜੇ': 222,\n",
              " 'ਦੂਰ': 492,\n",
              " 'ਦੇ': 11,\n",
              " 'ਦੇਖੀ': 397,\n",
              " 'ਦੇਖੇ': 589,\n",
              " 'ਦੇਣ': 643,\n",
              " 'ਦੇਰ': 67,\n",
              " 'ਦੇਵੇਗਾ': 620,\n",
              " 'ਦੇਸ਼': 60,\n",
              " 'ਦੇਹ': 319,\n",
              " 'ਦੋਵੇਂ': 136,\n",
              " 'ਦੋਸ਼': 277,\n",
              " 'ਦੋਸਤਾ': 555,\n",
              " 'ਧਨੰਤਰ': 627,\n",
              " 'ਧਰਤੀ': 488,\n",
              " 'ਧਰਮ': 114,\n",
              " 'ਧਿਆਨ': 647,\n",
              " 'ਧੀ': 572,\n",
              " 'ਧੰਨਿ': 102,\n",
              " 'ਨਈਂ': 622,\n",
              " 'ਨਕਸਲਬਾੜੀਆਂ': 569,\n",
              " 'ਨਤੀਜਾ': 484,\n",
              " 'ਨਦਰ': 682,\n",
              " 'ਨਸ਼ਿਆਂ': 693,\n",
              " 'ਨਹੀਂ': 13,\n",
              " 'ਨਾ': 22,\n",
              " 'ਨਾਂ': 675,\n",
              " 'ਨਾਨਾ': 472,\n",
              " 'ਨਾਨੀ': 473,\n",
              " 'ਨਾਲ': 19,\n",
              " 'ਨਿਕਲਦੇ': 451,\n",
              " 'ਨਿਵੇਸ਼': 535,\n",
              " 'ਨਿਸ਼ਾਨਾ': 692,\n",
              " 'ਨੀਂ': 275,\n",
              " 'ਨੁਮਾਇੰਦਿਆਂ': 251,\n",
              " 'ਨੂੰ': 10,\n",
              " 'ਨੇ': 24,\n",
              " 'ਨੇੜੇ': 452,\n",
              " 'ਨੈਗਲੀਜ਼ੇਬਲ': 562,\n",
              " 'ਨਜ਼ਰ': 395,\n",
              " 'ਨੰਬਰਦਾਰ': 630,\n",
              " 'ਪਤਾ': 490,\n",
              " 'ਪਪੀਤਾ': 646,\n",
              " 'ਪਰ': 35,\n",
              " 'ਪਰਤਿਆ': 250,\n",
              " 'ਪਰਿੰਦਾ': 521,\n",
              " 'ਪਲ': 413,\n",
              " 'ਪਵੇਗਾ': 625,\n",
              " 'ਪਹਿਲਾਂ': 95,\n",
              " 'ਪਹੁੰਚੀਆਂ': 248,\n",
              " 'ਪਹੁੰਚੇ': 497,\n",
              " 'ਪਾਉਣ': 368,\n",
              " 'ਪਾਉਣਾ': 194,\n",
              " 'ਪਾਤਰ': 564,\n",
              " 'ਪਾਰਕ': 155,\n",
              " 'ਪਾਵਰਫੁਲ': 700,\n",
              " 'ਪਿਆ': 53,\n",
              " 'ਪਿਤਾ': 307,\n",
              " 'ਪਿਰੁ': 344,\n",
              " 'ਪਿੰਡ': 337,\n",
              " 'ਪਿੱਛੋਂ': 162,\n",
              " 'ਪੀਣ': 128,\n",
              " 'ਪੀਵਾਂ': 274,\n",
              " 'ਪੁਆਓ': 330,\n",
              " 'ਪੁੱਤ': 680,\n",
              " 'ਪੁੱਤਰ': 650,\n",
              " 'ਪੁੱਤ੍ਰ': 317,\n",
              " 'ਪੂਜਾ': 391,\n",
              " 'ਪੂਰਾ': 476,\n",
              " 'ਪੂੰਜੀ': 256,\n",
              " 'ਪੈਨਸ਼ਨ': 378,\n",
              " 'ਪੈਸਾ': 653,\n",
              " 'ਪੈਸੇ': 47,\n",
              " 'ਪੈਗ਼ੰਬਰੀ': 449,\n",
              " 'ਪੋਸਟਮਾਰਟਮ': 245,\n",
              " 'ਪ੍ਰਕਾਰ': 542,\n",
              " 'ਪ੍ਰਭੁ': 299,\n",
              " 'ਪ੍ਰਾਪਤੀ': 438,\n",
              " 'ਪ੍ਰਿੰਸੀਪਲੀ': 420,\n",
              " 'ਪ੍ਰੇਤਾਂ': 604,\n",
              " 'ਪ੍ਰੇਸ਼ਾਨ': 431,\n",
              " 'ਪ੍ਰੋਫੈਸਰ': 464,\n",
              " 'ਪੰਜਾਬੀ': 465,\n",
              " 'ਪੱਕ': 678,\n",
              " 'ਪੱਕੀ': 400,\n",
              " 'ਪੱਗ': 204,\n",
              " 'ਫਰਕ': 199,\n",
              " 'ਫਲ': 645,\n",
              " 'ਫਾਰ': 561,\n",
              " 'ਫਿਫਟੀ': 112,\n",
              " 'ਫਿਰ': 100,\n",
              " 'ਫੀਸਦੀ': 362,\n",
              " 'ਫੁੱਟ': 229,\n",
              " 'ਫੁੱਲ': 628,\n",
              " 'ਫੇਰ': 166,\n",
              " 'ਫੈਸਲਾ': 254,\n",
              " 'ਫੋਨ': 282,\n",
              " 'ਬਗਲੀ': 236,\n",
              " 'ਬਗਾਵਤ': 513,\n",
              " 'ਬਣਾ': 619,\n",
              " 'ਬਣਾਈ': 696,\n",
              " 'ਬਣਾਏ': 221,\n",
              " 'ਬਣਿਆ': 356,\n",
              " 'ਬਣੀ': 304,\n",
              " 'ਬਣੇ': 295,\n",
              " 'ਬਦਕਿਸਮਤੀ': 656,\n",
              " 'ਬਦਲ': 271,\n",
              " 'ਬਦਲਦੇ': 687,\n",
              " 'ਬਦਲੇ': 309,\n",
              " 'ਬਰੰਗੇ': 426,\n",
              " 'ਬਲਦੇਵ': 189,\n",
              " 'ਬਲਵੰਤ': 184,\n",
              " 'ਬਹਿ': 394,\n",
              " 'ਬਹਿਆ': 614,\n",
              " 'ਬਹੁਤ': 36,\n",
              " 'ਬਾਅਦ': 56,\n",
              " 'ਬਾਪੂ': 349,\n",
              " 'ਬਾਰਡਰ': 454,\n",
              " 'ਬਾਰੇ': 252,\n",
              " 'ਬਾਹਰ': 146,\n",
              " 'ਬਾਹਰਲੇ': 575,\n",
              " 'ਬਿਮਾਰ': 493,\n",
              " 'ਬਿਲਕ': 587,\n",
              " 'ਬਿਲੀਅਨ': 436,\n",
              " 'ਬੁੱਢੇ': 266,\n",
              " 'ਬੂਟਾ': 228,\n",
              " 'ਬੂਹਾ': 290,\n",
              " 'ਬੇਹੋਸ਼': 308,\n",
              " 'ਬੇਹੱਦ': 699,\n",
              " 'ਬੈਕ': 629,\n",
              " 'ਬੈਠਾ': 127,\n",
              " 'ਬੈਠਿਆ': 690,\n",
              " 'ਬੈਠੋ': 83,\n",
              " 'ਬੋਲ': 450,\n",
              " 'ਬੋਲਦਾ': 417,\n",
              " 'ਬੋਲਦੇ': 567,\n",
              " 'ਬੋਲੋ': 160,\n",
              " 'ਬਖ਼ਸ਼': 318,\n",
              " 'ਬੜੀ': 511,\n",
              " 'ਬੰਦ': 291,\n",
              " 'ਬੰਦਈ': 639,\n",
              " 'ਬੰਦਾ': 85,\n",
              " 'ਬੰਦੇ': 72,\n",
              " 'ਬੰਨਾਂ': 205,\n",
              " 'ਬੰਬ': 240,\n",
              " 'ਬੱਚਾ': 408,\n",
              " 'ਬੱਚੇ': 58,\n",
              " 'ਭਰਨਾ': 624,\n",
              " 'ਭਲਾਈ': 469,\n",
              " 'ਭਾਂਡੇ': 315,\n",
              " 'ਭਾਅ': 357,\n",
              " 'ਭਾਗ': 342,\n",
              " 'ਭਾਦਸੋਂ': 292,\n",
              " 'ਭਾਰਤ': 243,\n",
              " 'ਭਾਸ਼ਾ': 566,\n",
              " 'ਭਿੰਡੀ': 227,\n",
              " 'ਭੀਮ': 355,\n",
              " 'ਭੁਕਾਨੇ': 427,\n",
              " 'ਭੁਗਤਣਾ': 487,\n",
              " 'ਭੁਨਾ': 219,\n",
              " 'ਭੁੱਖ': 586,\n",
              " 'ਭੁੱਲ': 508,\n",
              " 'ਭੂਤਾਂ': 603,\n",
              " 'ਭੈਅ': 108,\n",
              " 'ਭੋਜਨ': 615,\n",
              " 'ਭ੍ਰਿਸ਼ਟਾਚਾਰ': 276,\n",
              " 'ਮਗਰੋਂ': 455,\n",
              " 'ਮਤਲਬ': 559,\n",
              " 'ਮਨੁੱਖਤਾ': 150,\n",
              " 'ਮਨੁੱਖੀ': 239,\n",
              " 'ਮਰਦ': 549,\n",
              " 'ਮਰੂੰਡੇ': 220,\n",
              " 'ਮਸਲੇ': 640,\n",
              " 'ਮਹਾਂਭਾਰਤ': 353,\n",
              " 'ਮਾਂਬਾਪ': 588,\n",
              " 'ਮਾਈਕ': 456,\n",
              " 'ਮਾਤਰ': 414,\n",
              " 'ਮਾਤਾ': 328,\n",
              " 'ਮਾਨ': 458,\n",
              " 'ਮਾਨਸਿਕਤਾ': 686,\n",
              " 'ਮਾਮਲਾ': 398,\n",
              " 'ਮਾਮੂਲੀ': 301,\n",
              " 'ਮਾਰਿਆ': 595,\n",
              " 'ਮਾੜਾ': 158,\n",
              " 'ਮਿਟਾਉਣ': 200,\n",
              " 'ਮੀਂਹ': 591,\n",
              " 'ਮੀਠਾ': 300,\n",
              " 'ਮੁਕੰਦਪੁਰ': 419,\n",
              " 'ਮੁਸਕਰਾਓ': 207,\n",
              " 'ਮੁਹੰਮਦ': 93,\n",
              " 'ਮੁੰਡਾ': 74,\n",
              " 'ਮੁੱਕੀ': 613,\n",
              " 'ਮੂੰਹੋਂ': 448,\n",
              " 'ਮੇਰਾ': 97,\n",
              " 'ਮੇਰੀ': 612,\n",
              " 'ਮੇਰੀਆਂ': 676,\n",
              " 'ਮੇਰੇ': 45,\n",
              " 'ਮੈਂ': 78,\n",
              " 'ਮੈਚ': 153,\n",
              " 'ਮੈਨੂੰ': 27,\n",
              " 'ਮੋਢੇ': 346,\n",
              " 'ਮੌਕੇ': 186,\n",
              " 'ਮੌਜੂਦ': 188,\n",
              " 'ਮੰਗ': 201,\n",
              " 'ਮੰਨ': 370,\n",
              " 'ਮੰਨੀ': 509,\n",
              " 'ਮੱਦਦ': 556,\n",
              " 'ਯਾਦ': 359,\n",
              " 'ਯਾਦਾਂ': 525,\n",
              " 'ਯੁਵਕ': 468,\n",
              " 'ਯੋਗ': 124,\n",
              " 'ਰਚਾ': 393,\n",
              " 'ਰਜਾ': 324,\n",
              " 'ਰਲ': 242,\n",
              " 'ਰਵਾਇਤੀ': 565,\n",
              " 'ਰਸੋਈ': 522,\n",
              " 'ਰਹਿਣ': 621,\n",
              " 'ਰਹਿਣਾ': 326,\n",
              " 'ਰਹੀ': 262,\n",
              " 'ਰਹੇ': 28,\n",
              " 'ਰਹੇਗਾ': 389,\n",
              " 'ਰਾਂਝਣਾ': 681,\n",
              " 'ਰਾਜ': 429,\n",
              " 'ਰਾਜਧਾਨੀ': 258,\n",
              " 'ਰਾਮ': 322,\n",
              " 'ਰਾਸ਼ਟਰਪਤੀ': 528,\n",
              " 'ਰਿਸ਼ਤੇਦਾਰਾਂ': 554,\n",
              " 'ਰਿਹਾ': 130,\n",
              " 'ਰਿਹੈ': 423,\n",
              " 'ਰੀਸਾਈਕਲ': 616,\n",
              " 'ਰੁੱਤਾਂ': 460,\n",
              " 'ਰੋਕਣ': 694,\n",
              " 'ਰੋਟੀ': 498,\n",
              " 'ਰੋਲ': 183,\n",
              " 'ਰੰਗ': 425,\n",
              " 'ਰੰਗੀਨ': 512,\n",
              " 'ਰੱਖਣ': 648,\n",
              " 'ਰੱਖੋ': 655,\n",
              " 'ਰੱਜਵਾਂ': 461,\n",
              " 'ਰੱਬ': 325,\n",
              " 'ਲਈ': 21,\n",
              " 'ਲਓ': 175,\n",
              " 'ਲਗਾਤਾਰ': 116,\n",
              " 'ਲਟਕਾਏ': 428,\n",
              " 'ਲਫ਼ਜ਼': 159,\n",
              " 'ਲਵਾਇਆ': 407,\n",
              " 'ਲਵੋ': 557,\n",
              " 'ਲਹੂ': 272,\n",
              " 'ਲਾ': 347,\n",
              " 'ਲਾਇਆ': 652,\n",
              " 'ਲਾਗੈ': 298,\n",
              " 'ਲਾਭ': 642,\n",
              " 'ਲਾਸ਼ਾਂ': 246,\n",
              " 'ਲਿਆਵਾਂਗੇ': 206,\n",
              " 'ਲਿਖ': 422,\n",
              " 'ਲਿਖਵਾ': 140,\n",
              " 'ਲਿਖੀ': 421,\n",
              " 'ਲੀਡਰਾਂ': 507,\n",
              " 'ਲੇਟ': 385,\n",
              " 'ਲੈ': 62,\n",
              " 'ਲੈਂਦੀ': 284,\n",
              " 'ਲੈਂਦੀਆਂ': 539,\n",
              " 'ਲੋਕ': 50,\n",
              " 'ਲੋਕਾਂ': 486,\n",
              " 'ਲੜੀ': 673,\n",
              " 'ਲੱਗਦਾ': 90,\n",
              " 'ਲੱਗੀ': 96,\n",
              " 'ਲੱਡੂ': 381,\n",
              " 'ਵਧਾ': 379,\n",
              " 'ਵਰਗਾ': 532,\n",
              " 'ਵਰਤਣਾ': 164,\n",
              " 'ਵਰਤਮਾਨ': 412,\n",
              " 'ਵਰਤਾਰਾ': 152,\n",
              " 'ਵਸਿਆ': 660,\n",
              " 'ਵਸੀਲੇ': 286,\n",
              " 'ਵਾਂਗ': 59,\n",
              " 'ਵਾਦ': 440,\n",
              " 'ਵਾਪਰੀ': 482,\n",
              " 'ਵਾਪਸ': 249,\n",
              " 'ਵਾਲਾ': 644,\n",
              " 'ਵਾਲਾਂ': 537,\n",
              " 'ਵਾਲੀ': 514,\n",
              " 'ਵਾਲੇ': 144,\n",
              " 'ਵਾਸਤੇ': 654,\n",
              " 'ਵਿਆਂ': 672,\n",
              " 'ਵਿਆਹ': 607,\n",
              " 'ਵਿਕਾਸ': 149,\n",
              " 'ਵਿਚ': 20,\n",
              " 'ਵਿਚਲਾ': 198,\n",
              " 'ਵਿਚਾਰਾਂ': 170,\n",
              " 'ਵਿਭਾਗ': 466,\n",
              " 'ਵਿਰਦਾ': 348,\n",
              " 'ਵਿਰਾਇਆ': 345,\n",
              " 'ਵਿਵਾਦ': 441,\n",
              " 'ਵਿਸ਼ਵ': 257,\n",
              " 'ਵਿੱਚ': 34,\n",
              " 'ਵੀ': 7,\n",
              " 'ਵੀਰੋ': 84,\n",
              " 'ਵੇਲੇ': 280,\n",
              " 'ਵੋਟਾਂ': 366,\n",
              " 'ਵੰਡ': 113,\n",
              " 'ਵੰਡਦੇ': 382,\n",
              " 'ਵੱਖਰੀ': 668,\n",
              " 'ਵੱਧ': 581,\n",
              " 'ਵੱਲ': 523,\n",
              " 'ਸ਼ਕਤੀ': 202,\n",
              " 'ਸ਼ਾਕਾਹਾਰੀ': 212,\n",
              " 'ਸ਼ਾਮ': 66,\n",
              " 'ਸ਼ੈਂਪੂ': 161,\n",
              " 'ਸਕਦਾ': 244,\n",
              " 'ਸਕਦੇ': 65,\n",
              " 'ਸਕੀਮਾਂ': 215,\n",
              " 'ਸਕੂਟਰ': 364,\n",
              " 'ਸਟੀਕ': 689,\n",
              " 'ਸਟ੍ਰੈਟੇਜੀਜ਼': 560,\n",
              " 'ਸਤਿ': 517,\n",
              " 'ਸਤਿਕਾਰ': 515,\n",
              " 'ਸਤ੍ਹਾ': 536,\n",
              " 'ਸਦਾ': 387,\n",
              " 'ਸਨ': 12,\n",
              " 'ਸਨਦ': 608,\n",
              " 'ਸਭ': 94,\n",
              " 'ਸਰਕਲ': 293,\n",
              " 'ਸਰਕਾਰ': 377,\n",
              " 'ਸਰਕਾਰੀ': 214,\n",
              " 'ਸਰਗਰਮ': 340,\n",
              " 'ਸਰਚਾਂਦ': 187,\n",
              " 'ਸਹੀ': 510,\n",
              " 'ਸ਼ਰਤ': 369,\n",
              " 'ਸ਼ਹਿਰਾਂ': 138,\n",
              " 'ਸਾਈਕਲ': 363,\n",
              " 'ਸਾਡਾ': 446,\n",
              " 'ਸਾਡੀ': 583,\n",
              " 'ਸਾਡੇ': 168,\n",
              " 'ਸਾਥੀ': 585,\n",
              " 'ਸਾਧ': 296,\n",
              " 'ਸਾਰਾ': 593,\n",
              " 'ਸਾਰੀ': 480,\n",
              " 'ਸਾਰੇ': 38,\n",
              " 'ਸਾਲ': 70,\n",
              " 'ਸਾਹਿਬ': 75,\n",
              " 'ਸਾਹੀ': 416,\n",
              " 'ਸਿਆਸਤਦਾਨਾਂ': 570,\n",
              " 'ਸਿਕਾਰੀਆਂ': 225,\n",
              " 'ਸਿਖ਼ਰ': 444,\n",
              " 'ਸਿੰਗੇ': 531,\n",
              " 'ਸਿੰਘ': 32,\n",
              " 'ਸਿੱਖ': 87,\n",
              " 'ਸਿੱਧੀ': 601,\n",
              " 'ਸਿੱਧੇ': 210,\n",
              " 'ਸੀ': 6,\n",
              " 'ਸੀਟ': 401,\n",
              " 'ਸੀਰੀਅਲ': 354,\n",
              " 'ਸੁਆਦ': 594,\n",
              " 'ਸੁਣਦਾ': 631,\n",
              " 'ਸੁੰਦਰ': 151,\n",
              " 'ਸੁੱਤੀਆਂ': 635,\n",
              " 'ਸੂਰਜ': 109,\n",
              " 'ਸੈਂ': 180,\n",
              " 'ਸੈਨੇਸੈਂਸ': 563,\n",
              " 'ਸੈਲਜ਼': 558,\n",
              " 'ਸੋ': 209,\n",
              " 'ਸੌ': 361,\n",
              " 'ਸ੍ਰੀ': 518,\n",
              " 'ਸੰਗਿ': 297,\n",
              " 'ਸੰਗੀਤ': 582,\n",
              " 'ਸੰਦੇਸ਼': 530,\n",
              " 'ਸੰਪਾਦਕ': 516,\n",
              " 'ਸੰਭਾਲਿਆ': 459,\n",
              " 'ਸੱਟੀ': 578,\n",
              " 'ਸੱਭ': 483,\n",
              " 'ਹਨ': 9,\n",
              " 'ਹਮਾਰੇ': 341,\n",
              " 'ਹਮੇਸ਼ਾ': 599,\n",
              " 'ਹਰ': 86,\n",
              " 'ਹਰਣ': 463,\n",
              " 'ਹਰਭਜਨ': 457,\n",
              " 'ਹਾਂ': 42,\n",
              " 'ਹਾਕੀ': 626,\n",
              " 'ਹਾਲ': 447,\n",
              " 'ਹਾਸਾ': 502,\n",
              " 'ਹਿੰਦੀ': 260,\n",
              " 'ਹਿੱਕ': 651,\n",
              " 'ਹੀ': 15,\n",
              " 'ਹੀਲੇ': 285,\n",
              " 'ਹੁਣ': 77,\n",
              " 'ਹੁਣੇ': 247,\n",
              " 'ਹੁੰਦਾ': 115,\n",
              " 'ਹੁੰਦੀ': 122,\n",
              " 'ਹੁੰਦੀਆਂ': 606,\n",
              " 'ਹੈ': 3,\n",
              " 'ਹੈਰਾਨ': 478,\n",
              " 'ਹੋ': 30,\n",
              " 'ਹੋਇਆ': 49,\n",
              " 'ਹੋਈ': 306,\n",
              " 'ਹੋਏ': 80,\n",
              " 'ਹੋਣ': 143,\n",
              " 'ਹੋਣਾ': 443,\n",
              " 'ਹੋਣੇ': 156,\n",
              " 'ਹੋਰ': 373,\n",
              " 'ਹੋਵੇ': 663,\n",
              " 'ਹਜ਼ੂਰ': 203,\n",
              " 'ਹੰਝੂ': 273,\n",
              " 'ਹੱਟੀ': 543,\n",
              " 'ਹੱਥ': 432,\n",
              " 'ਹੱਥਾਂ': 314,\n",
              " 'ੇਪੀਰਵਰਗੀ': 553,\n",
              " 'ਗ਼ੁਲਾਮ': 335,\n",
              " 'ਜ਼ਰਦਾਰੀ': 529,\n",
              " 'ਜ਼ਾਹਰ': 269,\n",
              " 'ਜ਼ਿੰਦਗੀ': 584,\n",
              " 'ਜ਼ੀਰੋ': 439,\n",
              " 'ਫ਼ਰਜ਼ੀ': 390,\n",
              " 'ਫ਼ਿਲਮ': 695}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxNNgLvs8Tgh"
      },
      "source": [
        "#Padding of i/p, o/p, i/p to o/p sequences\n",
        "encoder_input_sequences = pad_sequences(aud_data, maxlen=max_input_len)\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnLoKzMh7tQD"
      },
      "source": [
        "encoder_input_sequences = encoder_input_sequences.reshape(161,73728,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmxdDwYv70vj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "545e74ef-6040-40f9-d607-bbc0bc20ec78"
      },
      "source": [
        "encoder_input_sequences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161, 73728)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69lOSWHQ8ToA"
      },
      "source": [
        "decoder_targets_one_hot = np.zeros((\n",
        "        161,\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my0nTMfsJg5F"
      },
      "source": [
        "decoder_targets_one_hot.shape\n",
        "\n",
        "for i, d in enumerate(decoder_output_sequences):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHB1PXs1_3zn"
      },
      "source": [
        "#encoder_inputs_placeholder = Input(shape=(161,1,max_input_len,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_HICvl2AL5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5066ac1-8652-49d3-9113-449c42d4a78c"
      },
      "source": [
        "#encoder_inputs_placeholder.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 161, 1, 73728])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls8CiXDW8Tuh"
      },
      "source": [
        "#Encoder part      \n",
        "encoder_inputs_placeholder = Input(shape=(None,1))\n",
        "#x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(LSTM_NODES,return_state=True)\n",
        "\n",
        "#encoder states\n",
        "encoder_outputs, h, c = encoder(encoder_inputs_placeholder)\n",
        "encoder_states = [h, c]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSulYofA9BJk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f61d94e-672d-416a-b93a-28f8c8c9da65"
      },
      "source": [
        "encoder_inputs_placeholder.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 73728, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RZrLy-78T08"
      },
      "source": [
        "#Decoder part\n",
        "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
        "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEAK1qpD8T7D"
      },
      "source": [
        "#Dense layer for softmax (final layer)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs_placeholder,\n",
        "  decoder_inputs_placeholder], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykppGkFuCccB"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaIwJ5Y78lFB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "4c656b1e-ac47-477b-86e9-32d0485b3ce2"
      },
      "source": [
        "r = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets_one_hot,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=8,\n",
        "    validation_split=0.1\n",
        ")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6ad910d75cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    804\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    798\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2945\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    749\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m           last_output, outputs, new_h, new_c, runtime = gpu_lstm(\n\u001b[0;32m-> 1177\u001b[0;31m               **gpu_lstm_kwargs)\n\u001b[0m\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m           last_output, outputs, new_h, new_c, runtime = standard_lstm(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgpu_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001b[0m\n\u001b[1;32m   1421\u001b[0m     outputs, h, c, _ = gen_cudnn_rnn_ops.cudnn_rnn(\n\u001b[1;32m   1422\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m         rnn_mode='lstm')\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m   \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[1;32m    101\u001b[0m           \u001b[0minput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_eager_fallback\u001b[0;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \"is_training\", is_training)\n\u001b[1;32m    179\u001b[0m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001b[0;32m--> 180\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 256, 1, 73728, 32, 256]  [Op:CudnnRNN]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCXqHb1wQR5P"
      },
      "source": [
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
        "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [h, c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bRYDJ-fQSJ9"
      },
      "source": [
        "#idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTdHBbSPQSYt"
      },
      "source": [
        "def translate_sentence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvNrfOsOfEIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "081d37be-9bba-490c-dcc5-bd94873eaf5f"
      },
      "source": [
        "states_value = encoder_model.predict(encoder_input_sequences[3].reshape(1,1,73728))\n",
        "states_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 1.9832416e-03, -2.9392836e-03, -2.7708495e-03, -2.3915293e-03,\n",
              "         -1.3431433e-03, -2.0549148e-03,  1.9918962e-03,  1.8797313e-03,\n",
              "         -1.4383299e-03,  3.0026499e-03,  1.4180391e-03, -1.8441672e-03,\n",
              "         -1.6917244e-03, -6.3298000e-03, -2.6564049e-03,  3.1166405e-03,\n",
              "          6.9447380e-04,  2.3725205e-03,  2.9290322e-04,  3.3212297e-03,\n",
              "          5.5863668e-04, -1.3160881e-03,  2.5751279e-03, -9.5557328e-04,\n",
              "          3.9126314e-03, -2.9484942e-03,  1.6063093e-03,  1.7228012e-03,\n",
              "         -2.3650743e-04,  1.0464938e-03,  2.0690663e-03, -4.1803614e-05,\n",
              "         -2.0837293e-03,  3.1804154e-03, -9.3866533e-05, -1.2077554e-03,\n",
              "         -2.3056786e-03,  3.2852050e-03,  2.9658568e-03,  2.0721594e-03,\n",
              "         -2.4969603e-03, -1.5396343e-03, -2.2479810e-03,  6.6872533e-05,\n",
              "         -2.8486291e-03,  3.3057588e-03, -2.6770008e-03, -3.2109372e-05,\n",
              "          1.0115480e-03,  2.3922769e-03, -1.0419845e-03,  2.3755596e-03,\n",
              "         -5.7630130e-04,  6.3022750e-04, -3.1923240e-03,  3.2478275e-03,\n",
              "          3.1945396e-03, -2.1657953e-03, -2.7881290e-03, -6.3909689e-04,\n",
              "          1.9956776e-03,  2.1582840e-03,  3.4480835e-03,  2.8494117e-03,\n",
              "          1.1572729e-04, -7.0966082e-04,  3.0305895e-03, -2.8752983e-03,\n",
              "         -2.7337826e-03, -2.7487522e-03,  7.8028778e-04,  1.2175456e-03,\n",
              "          2.8974568e-03,  3.0032014e-03,  5.7883090e-03,  1.8289668e-03,\n",
              "          1.9763210e-03, -6.0688333e-05,  2.3114763e-03, -9.2823881e-05,\n",
              "          3.1622390e-03,  1.5098087e-03,  1.2481580e-03, -8.4245560e-04,\n",
              "          2.0495206e-03,  3.0862106e-04, -2.8471097e-03, -6.4655714e-04,\n",
              "         -1.8647459e-03,  2.0033972e-04,  2.1359061e-03,  2.8687294e-03,\n",
              "         -6.7682384e-04,  1.7160168e-03, -2.6060767e-03, -5.1705068e-04,\n",
              "         -2.2226546e-03, -2.7844214e-03, -1.4307590e-03, -3.2532040e-03,\n",
              "         -8.1884535e-04, -5.6747743e-04, -4.4519533e-04, -1.6131796e-03,\n",
              "          2.9053679e-03, -3.0841285e-03,  3.0875113e-03, -8.4603947e-05,\n",
              "          3.4404453e-04,  3.1112274e-03, -1.0752794e-03, -3.2191661e-03,\n",
              "         -4.5953668e-04,  3.8279835e-04,  1.0777697e-03,  2.3115962e-03,\n",
              "         -3.1594124e-03,  2.9559145e-03, -2.1942079e-03,  2.5117057e-03,\n",
              "          2.9318763e-03,  5.0844136e-04, -2.5514143e-03, -3.3208211e-03,\n",
              "         -3.2105674e-03,  2.8693550e-03, -5.6982902e-03,  2.6284733e-03,\n",
              "          1.6615499e-03, -3.2487020e-03, -2.4738375e-03, -2.7853858e-03,\n",
              "          3.3767500e-03, -3.0323861e-03, -2.5334780e-03,  2.8936567e-03,\n",
              "         -2.6766888e-03,  1.4503718e-03, -2.9409050e-03,  2.6564347e-03,\n",
              "          2.7410579e-03, -2.8633138e-05,  4.5405457e-05, -2.4264276e-03,\n",
              "          7.2118820e-04, -7.7940605e-04,  2.0696379e-03, -3.5570681e-03,\n",
              "          2.5653536e-03, -2.4691902e-03, -1.4211126e-03, -3.9387536e-03,\n",
              "         -4.8086382e-04, -2.9198464e-03, -2.6408727e-03,  1.7205339e-03,\n",
              "          2.4393147e-03,  3.0796055e-03,  2.1838734e-03,  2.7011728e-03,\n",
              "         -4.7678747e-03, -3.5658192e-03,  1.7606023e-03, -3.1605216e-03,\n",
              "          2.9654282e-03,  2.6380338e-03, -2.5177555e-04, -1.1481749e-03,\n",
              "          7.6032517e-04,  2.4273482e-03, -1.2066915e-03,  1.0505719e-03,\n",
              "          2.5473153e-03,  1.2809666e-03, -2.6198458e-03,  5.7866448e-03,\n",
              "         -1.6562323e-03, -6.5083586e-04, -8.5743237e-03, -2.0366437e-03,\n",
              "         -1.4385296e-03,  2.6536162e-03,  1.7765396e-03, -3.0700320e-03,\n",
              "         -2.9997227e-03,  1.2383184e-04,  3.1289319e-04, -2.7539264e-03,\n",
              "         -2.3142567e-03,  5.8640086e-04, -3.3034504e-04, -2.1610383e-03,\n",
              "         -4.0077693e-03,  1.9857904e-03, -2.4329999e-03, -2.7829160e-03,\n",
              "          2.3976176e-03,  2.4468198e-03, -3.1936804e-03, -4.8063081e-03,\n",
              "          1.3565541e-03,  2.3700972e-03, -2.0626155e-03,  1.8728758e-03,\n",
              "          3.4096609e-03,  2.1815104e-03, -1.9407859e-03, -1.3285161e-03,\n",
              "         -1.5881545e-03, -3.1852173e-03,  2.3727315e-03, -2.0401021e-03,\n",
              "          2.6990103e-03, -7.2207302e-03,  2.7217269e-03, -4.7787977e-03,\n",
              "         -2.8545912e-03,  1.2417675e-04, -4.7744368e-03,  3.2663590e-03,\n",
              "         -2.1324314e-03,  4.5835563e-06,  3.6988125e-04,  4.9077999e-04,\n",
              "          1.8814813e-03, -1.9622419e-03, -1.6851784e-04, -2.5692943e-03,\n",
              "         -5.3215085e-04, -2.9904393e-03, -2.4830096e-03, -1.3385306e-03,\n",
              "         -2.8396910e-03, -3.0248566e-03,  1.3049076e-03,  2.5274439e-03,\n",
              "          8.4001449e-04,  2.3866727e-03,  6.6665350e-04,  2.6035476e-03,\n",
              "         -2.6737675e-03,  3.2514671e-04, -2.2357830e-03, -4.4793095e-03,\n",
              "         -2.3963614e-03,  2.5087937e-03, -1.8344009e-03, -6.4676203e-04,\n",
              "         -2.7645703e-03,  2.5871557e-03,  1.0307129e-03,  2.1742596e-03,\n",
              "          2.2343188e-03, -1.4006800e-03, -2.0953366e-03,  3.0837227e-03]],\n",
              "       dtype=float32),\n",
              " array([[ 3.97475017e-03, -5.88340266e-03, -5.55105926e-03,\n",
              "         -4.79207141e-03, -2.71122111e-03, -4.11945162e-03,\n",
              "          3.99476197e-03,  3.76893161e-03, -2.90415972e-03,\n",
              "          6.01130025e-03,  2.85483897e-03, -3.69941350e-03,\n",
              "         -3.39255296e-03, -1.25677949e-02, -5.32049825e-03,\n",
              "          6.23597018e-03,  1.40431104e-03,  4.75331116e-03,\n",
              "          5.91086922e-04,  6.64889533e-03,  1.13083341e-03,\n",
              "         -2.64256587e-03,  5.16590290e-03, -1.91873545e-03,\n",
              "          7.79766589e-03, -5.90148894e-03,  3.22170369e-03,\n",
              "          3.45700840e-03, -4.77618945e-04,  2.10104650e-03,\n",
              "          4.15072311e-03, -8.43053349e-05, -4.17787675e-03,\n",
              "          6.36801310e-03, -1.89625207e-04, -2.43745465e-03,\n",
              "         -4.62031784e-03,  6.57691155e-03,  5.93956513e-03,\n",
              "          4.15588403e-03, -5.00539737e-03, -3.09004891e-03,\n",
              "         -4.50583315e-03,  1.34495698e-04, -5.70831308e-03,\n",
              "          6.61675306e-03, -5.36247017e-03, -6.45848559e-05,\n",
              "          2.03107367e-03,  4.79474105e-03, -2.09159148e-03,\n",
              "          4.76206280e-03, -1.16644858e-03,  1.26636506e-03,\n",
              "         -6.38729287e-03,  6.50379481e-03,  6.39547454e-03,\n",
              "         -4.34107427e-03, -5.58480434e-03, -1.29410753e-03,\n",
              "          4.01430205e-03,  4.32672864e-03,  6.89883484e-03,\n",
              "          5.70310326e-03,  2.32764985e-04, -1.42627431e-03,\n",
              "          6.05976023e-03, -5.76100778e-03, -5.47661167e-03,\n",
              "         -5.50335832e-03,  1.56808342e-03,  2.46079639e-03,\n",
              "          5.80425840e-03,  6.01988658e-03,  1.15623977e-02,\n",
              "          3.66917462e-03,  3.96675477e-03, -1.22207915e-04,\n",
              "          4.63301921e-03, -1.86646794e-04,  6.33289805e-03,\n",
              "          3.02782329e-03,  2.50529009e-03, -1.69014011e-03,\n",
              "          4.10751533e-03,  6.20672654e-04, -5.70369978e-03,\n",
              "         -1.29808031e-03, -3.74040008e-03,  4.03631770e-04,\n",
              "          4.28162422e-03,  5.74519765e-03, -1.35997124e-03,\n",
              "          3.44261713e-03, -5.22183860e-03, -1.03900919e-03,\n",
              "         -4.45401343e-03, -5.57562336e-03, -2.87235831e-03,\n",
              "         -6.51555276e-03, -1.64571265e-03, -1.14545471e-03,\n",
              "         -8.97361140e-04, -3.24841775e-03,  5.81756933e-03,\n",
              "         -6.16008835e-03,  6.17983937e-03, -1.70570900e-04,\n",
              "          6.91727968e-04,  6.22702483e-03, -2.17320351e-03,\n",
              "         -6.44037733e-03, -9.24583583e-04,  7.73906533e-04,\n",
              "          2.16251425e-03,  4.63116588e-03, -6.32227119e-03,\n",
              "          5.91782015e-03, -4.39956971e-03,  5.03126346e-03,\n",
              "          5.87117160e-03,  1.02307554e-03, -5.11008082e-03,\n",
              "         -6.64707739e-03, -6.42749714e-03,  5.74441766e-03,\n",
              "         -1.13387285e-02,  5.26907435e-03,  3.33404168e-03,\n",
              "         -6.50409004e-03, -4.97574033e-03, -5.58137009e-03,\n",
              "          6.75609801e-03, -6.05898583e-03, -5.07611968e-03,\n",
              "          5.79231884e-03, -5.36120916e-03,  2.93240324e-03,\n",
              "         -5.88695891e-03,  5.31920837e-03,  5.48978802e-03,\n",
              "         -5.77208375e-05,  9.12816759e-05, -4.86365892e-03,\n",
              "          1.44943257e-03, -1.56616734e-03,  4.15576017e-03,\n",
              "         -7.11386837e-03,  5.13807265e-03, -4.94807865e-03,\n",
              "         -2.85258377e-03, -7.85355270e-03, -9.67980071e-04,\n",
              "         -5.84800215e-03, -5.28793829e-03,  3.45125468e-03,\n",
              "          4.88555850e-03,  6.17096713e-03,  4.37622983e-03,\n",
              "          5.41167054e-03, -9.50636994e-03, -7.12680956e-03,\n",
              "          3.52902547e-03, -6.32784888e-03,  5.93915628e-03,\n",
              "          5.28423535e-03, -5.05477481e-04, -2.30549183e-03,\n",
              "          1.52681186e-03,  4.86584101e-03, -2.42260937e-03,\n",
              "          2.10822048e-03,  5.10373665e-03,  2.58756266e-03,\n",
              "         -5.24914265e-03,  1.15204789e-02, -3.34158330e-03,\n",
              "         -1.31450244e-03, -1.69744268e-02, -4.08358825e-03,\n",
              "         -2.88598426e-03,  5.31493127e-03,  3.56467348e-03,\n",
              "         -6.13276195e-03, -6.00608066e-03,  2.49525532e-04,\n",
              "          6.29441289e-04, -5.50748268e-03, -4.63975966e-03,\n",
              "          1.17953506e-03, -6.64048013e-04, -4.33355803e-03,\n",
              "         -8.01181514e-03,  3.99706559e-03, -4.87432024e-03,\n",
              "         -5.59662934e-03,  4.80618095e-03,  4.90317773e-03,\n",
              "         -6.39094366e-03, -9.56558157e-03,  2.72365124e-03,\n",
              "          4.75036958e-03, -4.13464056e-03,  3.75345233e-03,\n",
              "          6.82154065e-03,  4.37168917e-03, -3.90676176e-03,\n",
              "         -2.66650249e-03, -3.18737305e-03, -6.37641456e-03,\n",
              "          4.75512678e-03, -4.08770377e-03,  5.40350191e-03,\n",
              "         -1.43240187e-02,  5.45175886e-03, -9.51222889e-03,\n",
              "         -5.71547030e-03,  2.49867968e-04, -9.50924307e-03,\n",
              "          6.53772661e-03, -4.27500065e-03,  9.24941833e-06,\n",
              "          7.43322482e-04,  9.87116946e-04,  3.77709465e-03,\n",
              "         -3.93463951e-03, -3.39527323e-04, -5.14870603e-03,\n",
              "         -1.07548665e-03, -5.98942023e-03, -4.97278245e-03,\n",
              "         -2.68722046e-03, -5.68877021e-03, -6.05417974e-03,\n",
              "          2.61927699e-03,  5.06390492e-03,  1.68687652e-03,\n",
              "          4.78457240e-03,  1.34811667e-03,  5.21454075e-03,\n",
              "         -5.36048925e-03,  6.54928386e-04, -4.48188605e-03,\n",
              "         -8.92793108e-03, -4.80910484e-03,  5.02999080e-03,\n",
              "         -3.68566043e-03, -1.30932347e-03, -5.53801097e-03,\n",
              "          5.18382993e-03,  2.07379251e-03,  4.36087698e-03,\n",
              "          4.47664456e-03, -2.80955108e-03, -4.23007365e-03,\n",
              "          6.17314130e-03]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkLQychdf4QL"
      },
      "source": [
        "target_seq = np.zeros((1, 1))\n",
        "target_seq[0, 0] = word2idx_outputs['<sos>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH5ps9ZJf65m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bc1b679-baa0-4cc6-8a4b-fd6f8fca1bbd"
      },
      "source": [
        "len([target_seq]+states_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38eLKNlcgVmt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "28946141-f66b-4be6-918f-d69749db32a0"
      },
      "source": [
        "output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "idx = np.argmax(output_tokens[0, 0, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CORExtagb6v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4dd758f-a4b5-4578-b854-4c02ff8505d2"
      },
      "source": [
        "output_tokens[0,0,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00172956, 0.00177001, 0.0012265 , 0.00176879, 0.00179913,\n",
              "       0.00179007, 0.00172425, 0.00175066, 0.00173131, 0.00167894,\n",
              "       0.00173386, 0.0017218 , 0.00169601, 0.00171647, 0.00174108,\n",
              "       0.00172376, 0.0017106 , 0.00170398, 0.00168645, 0.0016597 ,\n",
              "       0.0016996 , 0.00164338, 0.00166485, 0.00166291, 0.00164997,\n",
              "       0.00166033, 0.00165538, 0.00162656, 0.00162956, 0.00164341,\n",
              "       0.00166859, 0.00157233, 0.0016225 , 0.00164828, 0.00160538,\n",
              "       0.00156369, 0.00164907, 0.00163975, 0.00160102, 0.00160802,\n",
              "       0.00157536, 0.00156258, 0.00161845, 0.00157029, 0.00159541,\n",
              "       0.00158064, 0.00157209, 0.00152727, 0.00154338, 0.00160316,\n",
              "       0.00153571, 0.00158131, 0.00144898, 0.00157023, 0.00150381,\n",
              "       0.00149521, 0.00152402, 0.00155713, 0.00147589, 0.00152981,\n",
              "       0.00131439, 0.00150752, 0.00151958, 0.00151893, 0.00144352,\n",
              "       0.00152895, 0.00146882, 0.00148422, 0.00151166, 0.00150032,\n",
              "       0.00153442, 0.00151028, 0.00143375, 0.0015163 , 0.00145651,\n",
              "       0.00139373, 0.00153535, 0.00146905, 0.00149741, 0.0015372 ,\n",
              "       0.00156916, 0.00150714, 0.00143611, 0.00151871, 0.00151817,\n",
              "       0.0014619 , 0.00144736, 0.00153823, 0.00151486, 0.00153612,\n",
              "       0.00147015, 0.00146501, 0.00143915, 0.00143591, 0.00147419,\n",
              "       0.00145767, 0.00139194, 0.00153727, 0.00133417, 0.00151866,\n",
              "       0.00145641, 0.00153798, 0.00144064, 0.00151955, 0.00151691,\n",
              "       0.00151475, 0.0014245 , 0.00148954, 0.00150871, 0.00147769,\n",
              "       0.00155222, 0.00138666, 0.00148855, 0.00142445, 0.00145793,\n",
              "       0.00154631, 0.00146874, 0.0014084 , 0.00152657, 0.00154074,\n",
              "       0.0015349 , 0.00141504, 0.00154203, 0.00150002, 0.00153681,\n",
              "       0.00135246, 0.00145017, 0.00151515, 0.00138386, 0.00141498,\n",
              "       0.00149043, 0.00149946, 0.00151949, 0.00148146, 0.00141703,\n",
              "       0.00146135, 0.00135434, 0.00147366, 0.00136042, 0.00138459,\n",
              "       0.00146654, 0.00148949, 0.0013911 , 0.00139138, 0.00149285,\n",
              "       0.00134546, 0.00134563, 0.0014784 , 0.00146521, 0.00132918,\n",
              "       0.00133524, 0.00146394, 0.00144043, 0.00134951, 0.00140727,\n",
              "       0.00142053, 0.00146257, 0.00133779, 0.00145953, 0.00145084,\n",
              "       0.00148793, 0.00138022, 0.00141491, 0.00143788, 0.00146008,\n",
              "       0.00145807, 0.00133481, 0.00133688, 0.00144059, 0.00147221,\n",
              "       0.00138947, 0.00144118, 0.00136888, 0.00136143, 0.00145296,\n",
              "       0.00147922, 0.00146358, 0.0013431 , 0.00136413, 0.00140652,\n",
              "       0.0014316 , 0.00144376, 0.00141801, 0.00151175, 0.00135672,\n",
              "       0.00147035, 0.00137856, 0.0013921 , 0.00147045, 0.00134078,\n",
              "       0.00146548, 0.00148634, 0.00134776, 0.00138067, 0.00141739,\n",
              "       0.00144397, 0.00137116, 0.00137782, 0.0014061 , 0.00143437,\n",
              "       0.00145334, 0.00145133, 0.00146085, 0.00137563, 0.00143113,\n",
              "       0.00143021, 0.00147788, 0.00135465, 0.00140504, 0.00135096,\n",
              "       0.00142783, 0.00142598, 0.00147898, 0.00136622, 0.00139827,\n",
              "       0.00139683, 0.00147367, 0.00148907, 0.00133262, 0.00135775,\n",
              "       0.00142212, 0.00144408, 0.00132461, 0.00138158, 0.00144513,\n",
              "       0.00135588, 0.00143301, 0.00135756, 0.00141077, 0.0014542 ,\n",
              "       0.0014615 , 0.00134033, 0.00142612, 0.00146916, 0.00134878,\n",
              "       0.00142589, 0.00145263, 0.00150312, 0.00132385, 0.00132646,\n",
              "       0.00137124, 0.00143243, 0.00137568, 0.00143119, 0.0014769 ,\n",
              "       0.00134862, 0.00142866, 0.00142847, 0.00148241, 0.00145196,\n",
              "       0.00147626, 0.00140336, 0.00142414, 0.00145692, 0.00145101,\n",
              "       0.00133973, 0.00137886, 0.00142511, 0.00143132, 0.00135612,\n",
              "       0.00142271, 0.00148209, 0.00146421, 0.00134514, 0.00141023,\n",
              "       0.0014387 , 0.00136243, 0.00141056, 0.0014929 , 0.00133984,\n",
              "       0.00137983, 0.00144938, 0.00139042, 0.0014361 , 0.00148403,\n",
              "       0.0015061 , 0.00132286, 0.00137622, 0.00142989, 0.00144391,\n",
              "       0.00135049, 0.00146299, 0.00145694, 0.00147802, 0.00143277,\n",
              "       0.00136525, 0.00143921, 0.00147388, 0.00148891, 0.00134665,\n",
              "       0.00144927, 0.00144707, 0.00138805, 0.00143965, 0.00147206,\n",
              "       0.0014987 , 0.00133285, 0.00140961, 0.00144849, 0.00146852,\n",
              "       0.00148359, 0.001387  , 0.00142281, 0.00145039, 0.00149381,\n",
              "       0.00135248, 0.00140314, 0.00145482, 0.00147346, 0.00136115,\n",
              "       0.00139923, 0.00143582, 0.0014689 , 0.0014575 , 0.00140894,\n",
              "       0.00145545, 0.00144091, 0.00138069, 0.00145449, 0.00144865,\n",
              "       0.00149595, 0.00150034, 0.00134535, 0.00141227, 0.00144512,\n",
              "       0.00145843, 0.00148678, 0.00133113, 0.00135761, 0.00143437,\n",
              "       0.00147612, 0.00132325, 0.00146202, 0.0014214 , 0.00145685,\n",
              "       0.00148325, 0.00135203, 0.00145662, 0.0014709 , 0.00140049,\n",
              "       0.00147983, 0.00139426, 0.00139749, 0.00141986, 0.00146873,\n",
              "       0.00138696, 0.00142548, 0.00143147, 0.00147211, 0.00138004,\n",
              "       0.00146754, 0.00146886, 0.00147712, 0.00142532, 0.00143167,\n",
              "       0.00147214, 0.00146076, 0.00132572, 0.00138126, 0.00144617,\n",
              "       0.00135467, 0.00136861, 0.00141871, 0.0013478 , 0.0014186 ,\n",
              "       0.00150439, 0.00137687, 0.00136505, 0.00142895, 0.00141817,\n",
              "       0.00149424, 0.00140368, 0.00145468, 0.00141745, 0.00141547,\n",
              "       0.00147586, 0.00134583, 0.00137239, 0.0013824 , 0.00139586,\n",
              "       0.00139996, 0.00145372, 0.00146632, 0.00134248, 0.00138282,\n",
              "       0.00146231, 0.00147896, 0.00142591, 0.0014571 , 0.00149239,\n",
              "       0.00132012, 0.00135556, 0.00139045, 0.00145392, 0.0014588 ,\n",
              "       0.00136788, 0.00144472, 0.00147441, 0.00144718, 0.00136221,\n",
              "       0.00143574, 0.00144537, 0.00136537, 0.00142816, 0.00146312,\n",
              "       0.00134753, 0.00141522, 0.0014988 , 0.00135045, 0.00134533,\n",
              "       0.00141745, 0.00146106, 0.00133327, 0.00138506, 0.00145044,\n",
              "       0.00146252, 0.0013331 , 0.00145983, 0.00141688, 0.00142459,\n",
              "       0.00146562, 0.0014606 , 0.00141121, 0.00144902, 0.001335  ,\n",
              "       0.00136791, 0.00138272, 0.00143633, 0.00145426, 0.0013458 ,\n",
              "       0.00134847, 0.00147202, 0.00139601, 0.00145523, 0.00145049,\n",
              "       0.00135314, 0.00140099, 0.00141851, 0.00144378, 0.00146114,\n",
              "       0.00135074, 0.00137972, 0.00141259, 0.00144503, 0.00134341,\n",
              "       0.00134484, 0.00141157, 0.00148976, 0.00137765, 0.00141682,\n",
              "       0.00143292, 0.00143652, 0.00134302, 0.00139677, 0.00146482,\n",
              "       0.00138271, 0.00140683, 0.00141676, 0.00145305, 0.00147903,\n",
              "       0.00134135, 0.00142007, 0.00145589, 0.00146683, 0.00135034,\n",
              "       0.00137266, 0.00138915, 0.00145074, 0.00145702, 0.0014578 ,\n",
              "       0.00132952, 0.00135035, 0.00135341, 0.00137744, 0.00142657,\n",
              "       0.00145989, 0.00134205, 0.00139178, 0.00141635, 0.00141505,\n",
              "       0.00143271, 0.00147762, 0.00148252, 0.00138342, 0.00141977,\n",
              "       0.00145065, 0.00144488, 0.00148557, 0.00132169, 0.00144685,\n",
              "       0.00133299, 0.00144328, 0.00146521, 0.00134133, 0.00135739,\n",
              "       0.00140896, 0.00144797, 0.00134897, 0.0014115 , 0.00143116,\n",
              "       0.00147307, 0.00137797, 0.00146064, 0.0014675 , 0.00147459,\n",
              "       0.00137532, 0.00139471, 0.00138919, 0.00144102, 0.00144276,\n",
              "       0.00149244, 0.0014274 , 0.0014496 , 0.00141844, 0.00143169,\n",
              "       0.00134867, 0.00141058, 0.00146913, 0.00147981, 0.00147032,\n",
              "       0.00138015, 0.00143768, 0.00145545, 0.00149454, 0.00136501,\n",
              "       0.00144626, 0.00146889, 0.00135037, 0.0013817 , 0.00141316,\n",
              "       0.00151376, 0.00137342, 0.00143107, 0.00134951, 0.00144041,\n",
              "       0.00143367, 0.001377  , 0.00145046, 0.00148242, 0.00149319,\n",
              "       0.00133786, 0.00140312, 0.00146815, 0.0013204 , 0.00144905,\n",
              "       0.00134666, 0.0014505 , 0.00139805, 0.00146441, 0.00134068,\n",
              "       0.00135241, 0.00141195, 0.00144941, 0.00144971, 0.00137574,\n",
              "       0.00140961, 0.00145705, 0.00148152, 0.00132348, 0.00136301,\n",
              "       0.00141551, 0.00145013, 0.00145742, 0.00146516, 0.0013759 ,\n",
              "       0.00143595, 0.00146567, 0.00146798, 0.00132441, 0.00143611,\n",
              "       0.0013345 , 0.00143339, 0.00135564, 0.00141718, 0.00146391,\n",
              "       0.00137086, 0.00140347, 0.00145843, 0.00145879, 0.00133292,\n",
              "       0.00139296, 0.00143884, 0.00135626, 0.00138074, 0.00138022,\n",
              "       0.00146496, 0.00132637, 0.00138658, 0.00145279, 0.00145929,\n",
              "       0.00148204, 0.00132583, 0.00134803, 0.00143877, 0.00145097,\n",
              "       0.00145955, 0.00135208, 0.00135989, 0.00145223, 0.00132584,\n",
              "       0.00136212, 0.00138942, 0.00134553, 0.00135094, 0.00137642,\n",
              "       0.00147873, 0.00145489, 0.00135605, 0.00137618, 0.00141815,\n",
              "       0.00143161, 0.00135811, 0.00138705, 0.0014547 , 0.00134899,\n",
              "       0.00138834, 0.00136534, 0.0014218 , 0.00144902, 0.00147306,\n",
              "       0.0014643 , 0.00142163, 0.00144435, 0.00144038, 0.00144244,\n",
              "       0.00149838, 0.00137883, 0.00144808, 0.00143605, 0.00143415,\n",
              "       0.00132638, 0.00138835, 0.00140795, 0.00146329, 0.00133049,\n",
              "       0.00135774, 0.00140323, 0.0014663 , 0.00132986, 0.00136905,\n",
              "       0.00143953, 0.00124664, 0.00123828, 0.00122024, 0.00125018,\n",
              "       0.00125855, 0.00124219, 0.00123865, 0.00126021, 0.00122884,\n",
              "       0.00127017, 0.00123673, 0.00124578, 0.00121067, 0.00126945,\n",
              "       0.00124779, 0.00127252, 0.0012446 , 0.00124419, 0.00125595,\n",
              "       0.00122479, 0.0012453 , 0.00123919, 0.00125905, 0.00123755,\n",
              "       0.00125245, 0.00119925, 0.00122462, 0.00125058, 0.00122186,\n",
              "       0.00123607, 0.00125775, 0.00127229, 0.00123015, 0.00122934,\n",
              "       0.00122472, 0.00125121, 0.00124398, 0.00123561, 0.00121475,\n",
              "       0.00122509, 0.00125733, 0.00124626, 0.00122882, 0.00122944,\n",
              "       0.00123316, 0.00127513, 0.00122865, 0.0012299 , 0.00125416,\n",
              "       0.0012405 , 0.00125772, 0.00126344, 0.0012545 , 0.0012666 ,\n",
              "       0.00124235, 0.00126543, 0.0012607 , 0.00122735, 0.00124782,\n",
              "       0.00121769], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVgnD4SrgY0v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2be195ce-f0b3-4e0d-a54a-abdb32c5cc25"
      },
      "source": [
        "idx2word_target[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ਦੀ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlZZ9pUrKuwy"
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_rows = 4000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1xjFwrpQSe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e607eace-4c95-4284-da1e-49efeae4ce07"
      },
      "source": [
        "#|TESTIMG MODEL\n",
        "i = np.random.choice(len(aud_data))\n",
        "input_seq = encoder_input_sequences[i]\n",
        "#print(input_seq.shape)\n",
        "input_seq = input_seq.reshape(1,1,73728)\n",
        "text = translate_sentence(input_seq)\n",
        "print('-')\n",
        "print(i)\n",
        "#print('Input:', input_sentences[i])\n",
        "print('Response:', text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "147\n",
            "Response: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg0GmoZkdVa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "677f14f2-6c95-4baf-c5a9-152a23452d54"
      },
      "source": [
        "data.iloc[i,3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ਕੁੱਝ ਪੈਸਾ ਇਸ ਕੰਮ ਵਾਸਤੇ ਵੀ ਰੱਖੋ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}